{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " Ù¾Ø±Ù‡Ø§Ù… Ø¹Ø³Ú©Ø±Ø²Ø§Ø¯Ù‡\n",
    " Ø´Ù…Ø§Ø±Ù‡ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒÛŒ : Û¹Û¸Û±Û·Û°Û¹Û³Ûµ\n",
    "\n",
    "Ø¯Ø± Ø§ÛŒÙ† ØªÙ…Ø±ÛŒÙ† Ù…Ø§ Ù…ØªÙ† Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨ÙˆØ±Ø³ÛŒ Ø±Ø§ Ø§Ø² Ø³Ø§ÛŒØª Ø±Ù‡Ø§ÙˆØ±Ø¯ Û³Û¶Ûµ Ø¬Ù…Ø¹ Ù…ÛŒÚ©Ù†ÛŒÙ… Ùˆ Ø¨Ø± Ø±ÙˆÛŒ Ù…Ø±Ø§Ø­Ù„ Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø±Ø§ Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒÚ©Ù†ÛŒÙ… Ùˆ Ø¯Ø± Ø¢Ø®Ø± Ú¯Ø²Ø§Ø±Ø´ÛŒ Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ù†Ù† Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† ØªØ´Ø®ÛŒØµ Ù…ÛŒØ¯Ù‡ÛŒÙ… Ú©Ù‡ Ù…ØªÙ† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§Ø¬Ø¹ Ú©Ø¯Ø§Ù… Ø³Ù‡Ø§Ù… Ø¨ÙˆØ±Ø³ÛŒ Ø¨Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÛŒØ¯Ù‡Ø¯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù¾Ú©ÛŒØ¬ Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¨Ø±Ø§ÛŒ Ú©Ø±ÙˆÙ„ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø§ÛŒØª Ø±Ù‡Ø§ÙˆØ±Ø¯ Û³Û¶Ûµ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒÚ©Ù†ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from requests import ReadTimeout, TooManyRedirects, Timeout\n",
    "from requests.exceptions import ChunkedEncodingError, ConnectionError\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ù…ØªÙ† Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ù…Ø§ Ø§Ø² Ø¨Ø®Ø´ Ú¯ÙØªÚ¯Ùˆ Ù‡Ø§ÛŒ Ø³Ø§ÛŒØª Ø±Ù‡Ø§ÙˆØ±Ø¯ Û³Û¶Ûµ Ú©Ø±ÙˆÙ„ Ùˆ Ø¬Ù…Ø¹ Ø¢ÙˆØ±ÛŒ Ù…ÛŒØ´ÙˆÙ†Ø¯\n",
    " Ù‚Ø·Ø¹Ù‡ Ú©Ø¯ Ø²ÛŒØ± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø±ÙˆÙ„Ø± ØªÙ…Ø±ÛŒÙ† Ø§Ø³Øª:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class TweetCrawler:\n",
    "\n",
    "    def crawl_tweets(self, before_id=999999):\n",
    "        url = f'https://rahavard365.com/api/moreposts?before_id={before_id}'\n",
    "        headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36',\n",
    "            'sec-fetch-site': 'same-origin',\n",
    "            'sec-fetch-mode': 'cors',\n",
    "            'sec-fetch-dest': 'empty'\n",
    "        }\n",
    "        while True:\n",
    "            try:\n",
    "                response = requests.get(url, headers=headers, timeout=25)\n",
    "                if response.status_code == 429:\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "            except (Timeout, ReadTimeout, ConnectionError, TooManyRedirects, ChunkedEncodingError) as e:\n",
    "                time.sleep(30)\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "            result = json.loads(response.text)\n",
    "            return result['data'].get('posts')[random.randint(0, 19)]['body']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¨Ø§ Ø§Ø¬Ø±Ø§ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ† Ù…ØªØ¯ Ù…ØªÙ† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¬Ù…Ø¹ Ø´Ø¯Ù‡ Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ø±Ù†Ø¯ÙˆÙ… ÛŒÚ©ÛŒ Ø§Ø² Ø¢Ù†Ù‡Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒ Ø´ÙˆØ¯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ø³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TweetCrawler().crawl_tweets()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø­Ø§Ù„ Ø¨Ù‡ Ø¨Ø®Ø´ Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ù…ÛŒ Ø±Ø³ÛŒÙ… Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¹Ù„Ø§ÙˆÙ‡ Ø¨Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ú©ÛŒØ¬ Ù‡Ø¶Ù… Ø§Ø² Ù…ØªØ¯ Ù‡Ø§ÛŒ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø§ÛŒ Ú©Ù‡ Ú©Ø§Ø± Ù†Ø±Ù…Ø§Ù„ Ú©Ø±Ø¯Ù† Ùˆ ÛŒÚ©Ø³Ø§Ù† Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ùˆ Ù‡Ù…Ø¬Ù†ÛŒÙ† Ø­Ø°Ù stopowrd Ù‡Ø§ Ùˆ emoji Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒÚ©Ù†ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/nltk/parse/malt.py:183: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if ret is not 0:\n",
      "/usr/lib/python3.10/site-packages/nltk/ccg/chart.py:274: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if len(children) is 2:\n"
     ]
    }
   ],
   "source": [
    "from hazm import Normalizer\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "class SelfNormalizer:\n",
    "    def __init__(self):\n",
    "        self.normalizer = Normalizer()\n",
    "\n",
    "    def remove_shapes_and_convert_emojis_to_unicode(self, text: str):\n",
    "        shape_list = re.findall(r'[^\\w\\s,]', text)  # find all shape and emojis\n",
    "        for shape in shape_list:\n",
    "            shape_code = shape.encode('unicode-escape').decode('ASCII')\n",
    "            if 'U000' in shape_code:  # if the shape is an emoji\n",
    "                text = text.replace(shape, ' {} '.format(shape_code))\n",
    "            else:\n",
    "                text = text.replace(shape, ' ')\n",
    "        return text\n",
    "\n",
    "    def character_replacer(self, text: str):\n",
    "        # Numbers\n",
    "        text = re.sub(r'[Ù â“ªâ“¿ï¼ğŸ¶ğŸ„Œ]', 'Û°', text)\n",
    "        text = re.sub(r'[Ù¡â“µâ¶â€âŠê˜¡]', 'Û±', text)\n",
    "        text = re.sub(r'[Ù¢â‘¡ï¼’ğŸ]', 'Û²', text)\n",
    "        text = re.sub(r'[Ù£â‘¢ï¼“ğŸ›]', 'Û³', text)\n",
    "        text = re.sub(r'[Ù¤Û´â“¸âğŸ’ğŸœ]', 'Û´', text)\n",
    "        text = re.sub(r'[Ù¥â“¹âºï¼•ğŸ]', 'Ûµ', text)\n",
    "        text = re.sub(r'[Ù¦Û¶â‘¥â»ï¼–ğŸğŸ¨]', 'Û¶', text)\n",
    "        text = re.sub(r'[Ù§â†âï¼—ğŸŸ]', 'Û·', text)\n",
    "        text = re.sub(r'[Ù¨â‘§â½ï¼˜ğŸ–]', 'Û¸', text)\n",
    "        text = re.sub(r'[Ù©â‘¨â¾ğŸ—]', 'Û¹', text)\n",
    "\n",
    "        # Alphabet\n",
    "        text = re.sub(r'[Ø¢Ø£ğ¸€]', 'Ø§', text)\n",
    "        text = re.sub(r'[Ø¨ï­’ï­“ï­”ï­•ğ¸]', 'Ø¨', text)\n",
    "        text = re.sub(r'[ï­—ï­˜ï­™]', 'Ù¾', text)\n",
    "        text = re.sub(r'[Øªïº–ï­§ğ¸•]', 'Øª', text)\n",
    "        text = re.sub(r'[Ø«ïº™ïºšğ¸¶ğ¸–]', 'Ø«', text)\n",
    "        text = re.sub(r'[ïºïºïº ğ¸¢ğ¸‚]', 'Ø¬', text)\n",
    "        text = re.sub(r'[Ú†ï­»ï­¼ï®€]', 'Ú†', text)\n",
    "        text = re.sub(r'[Ø­ïº¢ïº£ğ¸‡]', 'Ø­', text)\n",
    "        text = re.sub(r'[ïº¦ïº¨ğ¸—]', 'Ø®', text)\n",
    "\n",
    "        text = re.sub(r'[Ø¯ïº©ïºª]', 'Ø¯', text)\n",
    "        text = re.sub(r'[Ø°ïº«ïº¬ğ¸˜]', 'Ø°', text)\n",
    "\n",
    "        text = re.sub(r'[Ø±ïº­ïº®ğ¸“]', 'Ø±', text)\n",
    "        text = re.sub(r'[Ø²à¢²ïº¯ïº°ğ¸†]', 'Ø²', text)\n",
    "        text = re.sub(r'[Ú˜ï®Šï®‹]', 'Ú˜', text)\n",
    "        text = re.sub(r'[ïº±ïº³ïº´ğ¸ğ¸®]', 'Ø³', text)\n",
    "        text = re.sub(r'[ïºµïº¶ïº¸ğ¸´ğ¸”]', 'Ø´', text)\n",
    "        text = re.sub(r'[Øµğ¸±ğ¸‘]', 'Øµ', text)\n",
    "        text = re.sub(r'[Ø¶ï»€ğ¸¹ğ¸™]', 'Ø¶', text)\n",
    "        text = re.sub(r'[ï»‚ï»ƒğ¸ˆ]', 'Ø·', text)\n",
    "        text = re.sub(r'[ï»†ğ¸š]', 'Ø¸', text)\n",
    "        text = re.sub(r'[Ø¹ï»‰ï»Šï»Œğ¸¯ğ¸]', 'Ø¹', text)\n",
    "        text = re.sub(r'[ï»ï»ï»ğ¸»ğ¸›]', 'Øº', text)\n",
    "        text = re.sub(r'[Ùğ¸ğ¸]', 'Ù', text)\n",
    "        text = re.sub(r'[ï»–ï»˜ğ¸Ÿğ¸’]', 'Ù‚', text)\n",
    "        text = re.sub(r'[Ú¯ï®“ï®”ï®•]', 'Ú¯', text)\n",
    "        text = re.sub(r'[Ùƒï®‘ğ¸Šğ¸ª]', 'Ú©', text)\n",
    "        text = re.sub(r'[ï»ï»ï»Ÿğ¸‹]', 'Ù„', text)\n",
    "        text = re.sub(r'[Ù…ï»¡ï»¤ğ¸¬ğ¸Œ]', 'Ù…', text)\n",
    "        text = re.sub(r'[ï»¥ğ¸ğ¸­]', 'Ù†', text)\n",
    "        text = re.sub(r'[ï»­ï»®ğ¸…Û…ï¯ ]', 'Ùˆ', text)\n",
    "        text = text.replace('ÙˆÙˆ', 'Ùˆ')\n",
    "        text = re.sub(r'[Ù‡ï®ªï»ªğ¸¤ï»«ï»¬]', 'Ù‡', text)\n",
    "        text = re.sub(r'[Ø©ïº”]', 'Ù‡', text)\n",
    "        text = re.sub(r'[Ù‰ï»¯ï»°ğ¸‰ï¯¨ï¯©]', 'ÛŒ', text)\n",
    "        text = text.replace('Ø¦ÛŒ', 'ÛŒÛŒ')\n",
    "        text = re.sub(r'[Ø¦ïº‰ïº‹]', 'Ø¦', text)\n",
    "        text = re.sub(r'[Ø¡ïº€Û½]', 'Ø¡', text)\n",
    "        text = text.replace('ï·¼', ' Ø±ÛŒØ§Ù„ ')\n",
    "\n",
    "        text = text.replace(' Ù…ÛŒ ', ' Ù…ÛŒ\\u200c')\n",
    "        text = text.replace(' Ù†Ù…ÛŒ ', ' Ù†Ù…ÛŒ\\u200c')\n",
    "        text = text.replace(' Ø¨Ø±Ù…ÛŒ ', ' Ø¨Ø±Ù…ÛŒ\\u200c')\n",
    "        text = text.replace(' Ø¨Ø±Ù†Ù…ÛŒ ', ' Ø¨Ø±Ù†Ù…ÛŒ\\u200c')\n",
    "\n",
    "        # Whitespace\n",
    "        text = re.sub(r'(\\r|\\f|\\v|\\\\r|\\\\n)+', '\\n', text)\n",
    "        text = re.sub(r'\\s?\\n\\s+', '\\n', text)\n",
    "        text = re.sub(r'[\\t]+', ' ', text)\n",
    "        text = re.sub(r' {2,}', ' ', text)\n",
    "\n",
    "        # semi-space\n",
    "        text = text.replace('&zwnj;', '\\u200c')\n",
    "        text = re.sub(r'[\\u2000-\\u200f]+', \"\\u200c\", text)\n",
    "        return text\n",
    "\n",
    "    def remove_stopword(self, text: str):\n",
    "        stop_words = ['Ø§Ø²', 'Ø¨Ù‡ ', 'Ø¨Ø§', ' Ù†Ù‡ ', 'Ø±Ø§', 'Ú©Ù‡ ', 'Ø¨ÙˆØ¯', 'Ø§Ø³Øª', 'Ù‡Ø³Øª', 'Ø´Ø¯', ' Ø¯Ø± ', 'Ø§Ú¯Ø± ', 'Ù‡Ù…Ú†Ù†ÛŒÙ† ',\n",
    "                      'Ú†Ù†ÛŒÙ† ', 'Ø¯Ø§Ø´Øª']\n",
    "        for word in stop_words:\n",
    "            text = re.sub(word, ' ', text)\n",
    "        return text\n",
    "\n",
    "    def normalize_with_hazm(self, text: str):\n",
    "        return self.normalizer.normalize(text)\n",
    "\n",
    "    def complete_normalize(self, text: str) -> str:\n",
    "        text = self.remove_shapes_and_convert_emojis_to_unicode(text)\n",
    "        text = self.character_replacer(text)\n",
    "        text = self.normalizer.normalize(text)\n",
    "        text = self.remove_stopword(text)\n",
    "\n",
    "        return text.strip()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ù…ÙˆØ¬ÛŒ Ù‡Ø§ Ùˆ Ø§Ø´Ú©Ø§Ù„ Ú©Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø§ Ù†Ø¯Ø§Ø±Ù†Ø¯ Ø§Ø² Ù…ØªÙ† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø­Ø°Ù Ù…ÛŒ Ø´ÙˆÙ†Ø¯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ø³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelfNormalizer().remove_shapes_and_convert_emojis_to_unicode()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø§ÛŒÙ† Ù…ØªØ¯ Ù‡Ù…Ø§Ù† Ú©Ø§Ø± Ù†Ø±Ù…Ø§Ù„ Ú©Ø±Ø¯Ù† Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ù¾Ú©ÛŒØ¬ÛŒ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ø³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelfNormalizer().character_replacer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ù…ØªØ¯ stopword Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø§Ø² Ù…ØªÙ† Ø­Ø°Ù Ù…ÛŒØ´ÙˆÙ†Ø¯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ø³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§ Ø¨Ú¯ÛŒØ¯'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelfNormalizer().remove_stopword()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ú©ÛŒØ¬ Ù‡Ø¶Ù… Ù…ØªÙ† Ø±Ø§ Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² Ù…ÛŒÚ©Ù†ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ø³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelfNormalizer().normalize_with_hazm()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø§ÛŒÙ† Ù…ØªØ¯ ØªØ¬Ù…ÛŒØ¹ÛŒ Ø§Ø² Ù…ØªØ¯ Ù‡Ø§ÛŒ Ø¨Ø§Ù„Ø§Ø³Øª Ú©Ù‡ Ù…ØªÙ† Ø±Ø§ Ù…ÛŒÚ¯ÛŒØ±Ø¯ Ùˆ Ø¹Ù…Ù„ Ù‡Ø§ÛŒ ÙÙˆÙ‚ Ø±Ø§ Ø±ÙˆÛŒ Ù…ØªÙ† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒØ¯Ù‡"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ø³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelfNormalizer().complete_normalize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¨Ø¹Ø¯ Ø§Ø² Ù†Ø±Ù…Ø§Ù„ Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ù†ÙˆØ¨Øª Ø¨Ù‡ Ú¯Ø±ÙØªÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² Ù…ØªÙ† Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡ Ù…ÛŒØ¨Ø§Ø´Ø¯\n",
    " Ù…Ø§ Ø¯Ø± Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ù‚Ø¨ÛŒÙ„ : Ù…Ù†Ø´Ù† Ù‡Ø§ Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù†Ù‡Ø§ ØŒ Ù‡Ø´ØªÚ¯ Ù‡Ø§ Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù†Ù‡Ø§ ØŒ Ø¹Ø¯Ø¯ Ù‡Ø§ Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù†Ù‡Ø§ Ø¯Ø§Ø®Ù„ Ù…ØªÙ† Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† Ù†Ù‚Ø´ Ú©Ù„Ù…Ø§Øª Ø¯Ø± Ø¬Ù…Ù„Ù‡ Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† ØªÙˆÚ©Ù† Ù‡Ø§ÛŒ Ø¬Ù…Ù„Ù‡ Ø±Ø§ Ø®Ø±ÙˆØ¬ÛŒ Ù…ÛŒØ¯Ù‡ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from hazm import POSTagger, SentenceTokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "class Analyzer:\n",
    "    def __init__(self):\n",
    "        self.sign = {\",\", \".\", \"ØŒ\", \"?\", \"ØŸ\", \"!\", \"!\", \"#\", \"*\", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \" \"}\n",
    "        self.sentence_tokenizer = SentenceTokenizer()\n",
    "        self.pos_tagger = POSTagger()\n",
    "\n",
    "    def mentions(self, text: str):\n",
    "        return list(set(re.findall('@([\\w_.]+)', text)))\n",
    "\n",
    "    def hashtags(self, text: str):\n",
    "        return list(set(re.findall('#([\\w_]+)', text)))\n",
    "\n",
    "    def numbers(self, text: str):\n",
    "        number = ''\n",
    "        numbers = []\n",
    "        for letter in text:\n",
    "            try:\n",
    "                int(letter)\n",
    "            except:\n",
    "                if len(number) != 0:\n",
    "                    numbers.append(number)\n",
    "                    number = ''\n",
    "                continue\n",
    "            number += letter\n",
    "        return numbers\n",
    "\n",
    "    def letter_info(self, text: str):\n",
    "        letters = []\n",
    "        namads = []\n",
    "        for letter in text:\n",
    "            if letter not in self.sign:\n",
    "                letters.append(letter)\n",
    "            elif letter != \" \":\n",
    "                namads.append(letter)\n",
    "        return {\"letter_count\": len(letters),\n",
    "                \"sign_count\": len(namads)}\n",
    "\n",
    "    def info_of_text(self, text: str):\n",
    "        return {\n",
    "                'numbers_info': {\n",
    "                    'numbers': self.numbers(text),\n",
    "                    'count': len(self.numbers(text))},\n",
    "                'letters_count': self.letter_info(text),\n",
    "                'hashtags_info': {\n",
    "                    'items': self.hashtags(text),\n",
    "                    'count': len(self.hashtags(text))},\n",
    "                'mentions_info': {\n",
    "                    'items': self.mentions(text),\n",
    "                    'count': len(self.mentions(text))}\n",
    "                }\n",
    "\n",
    "    def tokenizer(self, text: str):\n",
    "        return self.sentence_tokenizer.tokenize(text)\n",
    "\n",
    "    def postagger(self, text):\n",
    "        return self.pos_tagger.tag(text)\n",
    "\n",
    "    def rate_keywords(self, text):\n",
    "        rate = Counter(text.split())\n",
    "        all = sum(dict(rate).values())\n",
    "        info_rate = {}\n",
    "        for word in rate:\n",
    "            info_rate[word] = round(float((rate[word] / all) * 100), 2)\n",
    "        return info_rate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ø§ Ù…Ù†Ø´Ù† Ù‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ Ù…ØªÙ† Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù†Ù‡Ø§ Ø±Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ù…ÛŒÚ¯ÛŒØ±ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Model.__del__ at 0x7f4acadeda20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/site-packages/wapiti/api.py\", line 289, in __del__\n",
      "    if _wapiti and self._model:\n",
      "AttributeError: 'Model' object has no attribute '_model'\n",
      "Exception ignored in: <function Model.__del__ at 0x7f4acadeda20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/site-packages/wapiti/api.py\", line 289, in __del__\n",
      "    if _wapiti and self._model:\n",
      "AttributeError: 'Model' object has no attribute '_model'\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "argument 2: <class 'TypeError'>: wrong type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mArgumentError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [46]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mAnalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mmentions(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mØ³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [45]\u001B[0m, in \u001B[0;36mAnalyzer.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msign \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØŒ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØŸ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentence_tokenizer \u001B[38;5;241m=\u001B[39m SentenceTokenizer()\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_tagger \u001B[38;5;241m=\u001B[39m \u001B[43mPOSTagger\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/site-packages/hazm/SequenceTagger.py:23\u001B[0m, in \u001B[0;36mSequenceTagger.__init__\u001B[0;34m(self, patterns, **options)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, patterns\u001B[38;5;241m=\u001B[39m[], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions):\n\u001B[1;32m     22\u001B[0m \t\u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwapiti\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[0;32m---> 23\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/site-packages/wapiti/api.py:283\u001B[0m, in \u001B[0;36mModel.__init__\u001B[0;34m(self, patterns, encoding, **options)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatterns \u001B[38;5;241m=\u001B[39m patterns\n\u001B[0;32m--> 283\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model \u001B[38;5;241m=\u001B[39m \u001B[43m_wapiti\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_new_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpointer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatterns\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mArgumentError\u001B[0m: argument 2: <class 'TypeError'>: wrong type"
     ]
    }
   ],
   "source": [
    "Analyzer().mentions('Ø³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ø§ Ù‡Ø´ØªÚ¯ Ù‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ Ù…ØªÙ† Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù†Ù‡Ø§ Ø±Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ù…ÛŒÚ¯ÛŒØ±ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument 2: <class 'TypeError'>: wrong type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mArgumentError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [30]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mAnalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mhashtags(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mØ³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [28]\u001B[0m, in \u001B[0;36mAnalyzer.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msign \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØŒ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØŸ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentence_tokenizer \u001B[38;5;241m=\u001B[39m SentenceTokenizer()\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_tagger \u001B[38;5;241m=\u001B[39m \u001B[43mPOSTagger\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/site-packages/hazm/SequenceTagger.py:23\u001B[0m, in \u001B[0;36mSequenceTagger.__init__\u001B[0;34m(self, patterns, **options)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, patterns\u001B[38;5;241m=\u001B[39m[], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions):\n\u001B[1;32m     22\u001B[0m \t\u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwapiti\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[0;32m---> 23\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/site-packages/wapiti/api.py:283\u001B[0m, in \u001B[0;36mModel.__init__\u001B[0;34m(self, patterns, encoding, **options)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatterns \u001B[38;5;241m=\u001B[39m patterns\n\u001B[0;32m--> 283\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model \u001B[38;5;241m=\u001B[39m \u001B[43m_wapiti\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_new_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpointer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatterns\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mArgumentError\u001B[0m: argument 2: <class 'TypeError'>: wrong type"
     ]
    }
   ],
   "source": [
    "Analyzer().hashtags()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ø§ Ø¹Ø¯Ø¯ Ù‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ Ù…ØªÙ† Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù†Ù‡Ø§ Ø±Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ù…ÛŒÚ¯ÛŒØ±ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Analyzer().numbers()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù…Ø§ ØªØ¹Ø¯Ø§Ø¯ Ø­Ø±ÙˆÙÙˆ Ù†Ø´Ø§Ù†Ù‡ Ù‡Ø§ÛŒ Ø¯Ø§Ø®Ù„ Ù…ØªÙ† Ø±Ø§ Ø®Ø±ÙˆØ¬ÛŒ Ù…ÛŒÚ¯ÛŒØ±ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Analyzer().letter_info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ØªØ¯ Ù‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ Ø±Ø§Ø¨Ù‡ ØµÙˆØ±Øª ØªØ¬Ù…ÛŒØ¹ÛŒ Ùˆ ÛŒÚ©Ø¬Ø§ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒ Ø¯Ù‡Ø¯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument 2: <class 'TypeError'>: wrong type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mArgumentError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [36]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mAnalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39minfo_of_text(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mØ³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [33]\u001B[0m, in \u001B[0;36mAnalyzer.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msign \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØŒ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØŸ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentence_tokenizer \u001B[38;5;241m=\u001B[39m SentenceTokenizer()\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_tagger \u001B[38;5;241m=\u001B[39m \u001B[43mPOSTagger\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/site-packages/hazm/SequenceTagger.py:23\u001B[0m, in \u001B[0;36mSequenceTagger.__init__\u001B[0;34m(self, patterns, **options)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, patterns\u001B[38;5;241m=\u001B[39m[], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions):\n\u001B[1;32m     22\u001B[0m \t\u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwapiti\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[0;32m---> 23\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/site-packages/wapiti/api.py:283\u001B[0m, in \u001B[0;36mModel.__init__\u001B[0;34m(self, patterns, encoding, **options)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatterns \u001B[38;5;241m=\u001B[39m patterns\n\u001B[0;32m--> 283\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model \u001B[38;5;241m=\u001B[39m \u001B[43m_wapiti\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_new_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpointer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatterns\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mArgumentError\u001B[0m: argument 2: <class 'TypeError'>: wrong type"
     ]
    }
   ],
   "source": [
    "Analyzer().info_of_text()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø±Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ú©ÛŒØ¬ Ù‡Ø¶Ù… Ø¬Ù…Ù„Ù‡ Ø±Ø§ Ø¨Ù‡ ØªÙˆÚ©Ù† Ù‡Ø§ ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒÚ©Ù†ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Analyzer().tokenizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù†Ù‚Ø´ Ø¯Ø³ØªÙˆØ±ÛŒ Ú©Ù„Ù…Ø§Øª Ø¯Ø± Ù…ØªÙ† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ú©ÛŒØ¬ Ù‡Ø¶Ù… Ù…Ø´Ø®Øµ Ù…ÛŒØ´ÙˆØ¯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Analyzer().postagger()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† Ù…ØªØ¯ Ù…Ø§ Ø¯Ø±ØµØ¯ Ú©Ù„Ù…Ø§Øª Ø¨Ù‡ Ú©Ø§Ø± Ø±ÙØªÙ‡ Ø¯Ø± Ù…ØªÙ† Ø±Ø§ ØªØ´Ø®ÛŒØµ Ù…ÛŒ Ø¯Ù‡ÛŒÙ… Ú©Ù‡ Ø§ÛŒÙ† Ø¨Ù‡ Ù…Ø§ Ú©Ù…Ú© Ù…ÛŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¨ØªÙˆØ§Ù†ÛŒÙ… Ø±Ø§Ø¬Ø¹ Ø³Ù‡Ù… Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ù‚ÛŒÙ‚ ØªØ±ÛŒ Ø§Ø² Ù‚Ø¨ÛŒÙ„ ØªØ´Ø®ÛŒØµ Ù…ÛŒØ²Ø§Ù† Ø±Ø´Ø¯ ØŒ Ù†Ø²ÙˆÙ„ ØŒ Ù†ÙˆØ³Ø§Ù† Ø³Ù‡Ø§Ù… Ø¨Ú¯ÛŒØ±ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument 2: <class 'TypeError'>: wrong type",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mArgumentError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[0;32mIn [42]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mAnalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mrate_keywords(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mØ³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [33]\u001B[0m, in \u001B[0;36mAnalyzer.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msign \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØŒ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m?\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mØŸ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m!\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m{\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentence_tokenizer \u001B[38;5;241m=\u001B[39m SentenceTokenizer()\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_tagger \u001B[38;5;241m=\u001B[39m \u001B[43mPOSTagger\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/site-packages/hazm/SequenceTagger.py:23\u001B[0m, in \u001B[0;36mSequenceTagger.__init__\u001B[0;34m(self, patterns, **options)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, patterns\u001B[38;5;241m=\u001B[39m[], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions):\n\u001B[1;32m     22\u001B[0m \t\u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwapiti\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[0;32m---> 23\u001B[0m \t\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatterns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/site-packages/wapiti/api.py:283\u001B[0m, in \u001B[0;36mModel.__init__\u001B[0;34m(self, patterns, encoding, **options)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    281\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatterns \u001B[38;5;241m=\u001B[39m patterns\n\u001B[0;32m--> 283\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_model \u001B[38;5;241m=\u001B[39m \u001B[43m_wapiti\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_new_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpointer\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatterns\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mArgumentError\u001B[0m: argument 2: <class 'TypeError'>: wrong type"
     ]
    }
   ],
   "source": [
    "Analyzer().rate_keywords('Ø³Ù„Ø§Ù… Ø¯ÙˆØ³ØªØ§Ù† Ù…Ù† Ø§Ù…Ø±ÙˆØ² ÙˆØ±ÙˆØ¯ Ú©Ø±Ø¯Ù… Ù†Ø¸Ø²ØªÙˆÙ† Ø±Ùˆ ØµØ§Ø¯Ù‚Ø§Ù†Ù‡ Ø¨Ú¯ÛŒØ¯')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø¢Ø®Ø± Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚ÙˆØ§Ø¹Ø¯ Ø²Ø¨Ø§Ù† Ù…Ù†Ø¸Ù… Ù†Ø§Ù… Ø³Ù‡Ù… Ù‡Ø§ Ùˆ Ù†Ù…Ø§Ø¯ Ù‡Ø§ Ø±Ø§ Ø¯Ø§Ø®Ù„ Ù…ØªÙ† ØªØ´Ø®ÛŒØµ Ù…ÛŒØ¯Ù‡ÛŒÙ…"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def select_symbol_of_bourse(content: str):\n",
    "        symbols = {'ÙˆØªØ¬Ø§Ø±Øª', 'ÙˆÙ¾Ø§Ø±Ø³', 'ÙÙ…Ù„ÛŒ', 'ÙˆØ¨ØµØ§Ø¯Ø±', 'Ú©ØªØ±Ø§Ù…', 'ÙØ§Ø°Ø±', 'Ø´Ø±Ø§Ø²', 'Ú†Ú©Ø§Ù¾Ø§', 'Ø¢Ù¾', 'Ù„Ø§Ø¨Ø³Ø§', 'Ú©Ø§Ù…Ø§',\n",
    "                   'Ù¾Ú©ÙˆÛŒØ±', 'Ø«Ø¨Ù‡Ø³Ø§Ø²', 'Ú©Ù„Ø±', 'Ù¾ØªØ±ÙˆÙ„',\n",
    "                   'ÙˆØ±Ù†Ø§', 'Ù„Ú©Ù…Ø§', 'Ø¨ØªØ±Ø§Ù†Ø³', 'Ú©Ø³Ø±Ø§', 'Ø®ÙÙ†Ø±', 'Ø°ÙˆØ¨', 'Ø®Ø¯ÛŒØ²Ù„', 'Ø´Ø³ØªØ§', 'Ø´Ø§Ø±Ø§Ú©', 'ÙÙˆÙ„Ø§Ø¯', 'Ø´Ù¾ØªØ±Ùˆ',\n",
    "                   'ÙˆØ´Ù‡Ø±',\n",
    "                   'Ù‚Ø§Ø³Ù…', 'Ù¾Ø§Ù„Ø§ÛŒØ´', 'Ø®Ø³Ø§Ù¾Ø§', 'Ù¾Ø§Ø³Ø§', 'ÙØ³Ø¨Ø²ÙˆØ§Ø±', 'ÙˆØ¨Ø±Ù‚', 'ØºØ²Ø±', 'Ø³ÙØ§Ø±', 'Ù†ÙˆØ±ÛŒ', 'Ø²Ú¯Ù„Ø¯Ø´Øª', 'ÙˆÙ„Ø³Ø§Ù¾Ø§',\n",
    "                   'ÙˆØºØ¯ÛŒØ±', 'Ø³Ù¾ÛŒØ¯', 'ÙˆØ¢ÛŒÙ†Ø¯', 'Ø¨Ú©Ø§Ø¨', 'ÙˆØ³Ø§Ù„Øª', 'Ú©ÛŒØ³ÙˆÙ†', 'ØªÙ¾Ú©Ùˆ', 'Ø¨Ø¬Ù‡Ø±Ù…', 'ÙØ±ÙˆÛŒ', 'Ø®ØªØ±Ø§Ú©', 'Ù‡Ù…Ø±Ø§Ù‡',\n",
    "                   'ØºØ¨Ø´Ù‡Ø±',\n",
    "                   'ØºÙ†ÙˆØ´', 'Ú©ÛŒÙ…ÛŒØ§ØªÚ©', 'ÙÙ„ÙˆÙ„Ù‡', 'ØªÙØ§Ø±Ø³-Ù¾Ø°ÛŒØ±Ù‡', 'Ø¢Ø±Ø§Ù…', 'Ø®ÙÙˆÙ„Ø§', 'Ø¨Ø§Ù„Ø§Ø³', 'ØºØ¯Ø´Øª', 'Ø«Ø´Ø§Ù‡Ø¯',\n",
    "                   'Ú©ØªÙˆÚ©Ø§', 'Ú©ÙÙ¾Ø§Ø±Ø³', 'Ø²Ù…Ø§Ù‡Ø§Ù†', 'Ø´ÙÙ†', 'Ø¯ÛŒ', 'Ø®Ù¾Ø§Ø±Ø³', 'ØºØµÛŒÙ†Ùˆ', 'Ù…Ø§Ø¯ÛŒØ±Ø§', 'Ø²Ø§Ú¯Ø±Ø³', 'Ù‚Ú†Ø§Ø±', 'Ú©Ø±Ù…Ø§Ù†',\n",
    "                   'Ø´Ú©Ù„Ø±', 'Ø´Ù¾Ù„ÛŒ', 'Ø®Ú©Ø±Ù…Ø§Ù†', 'Ú©Ø¯Ù…Ø§', 'Ø·Ù„Ø§', 'Ø®Ù†ØµÛŒØ±', 'ÙˆÙ‡Ø§Ù…ÙˆÙ†Ø­', 'Ø´Ù„Ø±Ø¯', 'Ø¨Ø±Ú©Øª', 'Ú©Ù…Ù†Ø¯', 'ÙˆØ³ÛŒÙ†',\n",
    "                   'Ø³Ø¬Ø§Ù…',\n",
    "                   'Ù…ÙØ§Ø®Ø±', 'Ø´ÙˆÛŒÙ†Ø¯Ù‡', 'Ø®Ú©Ø§Ø±', 'Ø´ÛŒØ´Ù‡01Ù†', 'Ø§ÙÙ‚', 'Ø´Ù¾Ø¯ÛŒØ³', 'Ø®Ø§ÙˆØ±', 'ØªÙ…Ø­Ø±Ú©Ù‡', 'Ú©Ø§Ù„Ø§', 'ØµØ¨Ø§', 'Ø³ÛŒÙ…Ø±Øº',\n",
    "                   'Ø³Ù…Ú¯Ø§',\n",
    "                   'Ø²Ú¯Ù„Ø¯Ø´ØªØ­', 'Ø®Ú©Ù…Ú©', 'ÙØ²Ø±ÛŒÙ†', 'ÙÙ†ÙØª', 'Ø±ØªØ§Ù¾', 'Ø¯Ø§Ø±Ø§ ÛŒÚ©Ù…', 'Ø®Ú¯Ø³ØªØ±', 'ÙˆØ¢Ø°Ø±', 'Ø³Ø§Ø°Ø±ÛŒ', 'Ø®ÙˆØ¯Ú©ÙØ§',\n",
    "                   'ØºØ§Ù„Ø¨Ø±',\n",
    "                   'Ø¨Ø²Ø§Ú¯Ø±Ø³', 'ØºØ´Ù‡Ø¯Ø§Ø¨', 'ÙˆØ³Ø§Ù¾Ø§', 'Ù‚Ù†ÛŒØ´Ø§', 'Ú©Ú¯Ø§Ø²', 'ÙÙˆÙ„Ø§ÛŒ', 'ÙˆÙ¾Ø³Øª', 'Ø®ÙˆØ¯Ø±Ùˆ', 'Ø´Ú¯ÙˆÛŒØ§', 'Ø®Ù„Ù†Øª', 'Ø«Ø§Ø®Øª',\n",
    "                   'Ø´Ù¾Ù†Ø§', 'Ø´ØªØ±Ø§Ù†', 'ØºÚ¯Ø±Ø¬ÛŒ', 'ÙˆØ¨Ù…Ù„Øª', 'Ø³ÛŒØªØ§', 'Ú¯Ø´Ø§Ù†', 'ÙˆÚ¯Ø±Ø¯Ø´', 'ÙˆØ³Ø¯ÛŒØ¯'}\n",
    "\n",
    "        symbol_of_content = []\n",
    "        for symbol in symbols:\n",
    "            if symbol == 'Ø¯ÛŒ':\n",
    "                if content.startswith('Ø¯ÛŒ ') or content.endswith(' Ø¯ÛŒ') or ' Ø¯ÛŒ ' in content:\n",
    "                    symbol_of_content.append(symbol)\n",
    "                else:\n",
    "                    continue\n",
    "            if symbol in content:\n",
    "                symbol_of_content.append(symbol)\n",
    "\n",
    "        if len(symbol_of_content):\n",
    "            symbol_of_content = 'nothing'\n",
    "        return symbol_of_content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¨Ø§ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ù…ØªÙ† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¯Ø± ØªØ§Ø¨Ø¹ Ø²ÛŒØ± Ø³Ù‡Ù… Ù‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Ù…ØªÙ† Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒØ´ÙˆØ¯"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_symbol_of_bourse()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Ø¯Ø± Ø§ÛŒÙ† ØªÙ…Ø±ÛŒÙ† Ø³Ø¹ÛŒ Ø´Ø¯Ù‡ Ø®ÙˆØ§Ø³ØªÙ‡ Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø¯Ø± Ø¯Ø§Ú© ØªÙ…Ø±ÛŒÙ† Ø¨Ù‡ Ø®ÙˆØ¨ÛŒ Ù¾ÛŒØ§Ø¯Ù‡ Ø³Ø§Ø²ÛŒ Ø´ÙˆØ¯\n",
    " Ø¨Ø§ ØªØ´Ú©Ø± Ø§Ø² Ø­Ø³Ù† Ù†Ø¸Ø± Ø´Ù…Ø§Ø§Ø³ØªØ§Ø¯ Ú¯Ø±Ø§Ù…ÛŒ"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}